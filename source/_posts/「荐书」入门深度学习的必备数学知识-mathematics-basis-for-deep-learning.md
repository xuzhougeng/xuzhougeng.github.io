---
title: 「荐书」入门深度学习的必备数学知识
date: 2021-11-24 05:33:41.559
updated: 2021-11-24 05:41:53.663
url: /archives/mathematics-basis-for-deep-learning
categories: 其他
tags: 读书
---

以我浅薄的理解，深度学习是机器学习的一个子集。想要入门深度学习，可以先从最基础的神经网络开始。

神经网络也称之为多层感知机(multi-layer perceptron, MLP)，由输入层，隐藏层，输出层构成。最简单的神经网络只需要3层，拥有数百到数千个参数，而现代复杂的神经网络则可能有成千万上百万层，拥有数万，数十万，数百万的参数，例如人工智能公司OpenAI在2020年7月发布的GPT-3拥有1750亿个参数。对于那么多层的神经网络的训练，我们就称之为深度学习(deep learning).

目前关于深度学习的框架很多，包括但不限于MXNET, PyTorch, TensorFlow等，因此利用这些框架训练一个手写数字识别，猫和狗分类的神经网络并不算特别困难。但是如果我们有更高的追求，就得了解下它背后的数学基础。

目前阅读到大部分课程，虽然都会提到深度学习所需要的数学知识，例如线性代数，微积分，概率论和信息论，但是要么受限于篇幅没有详细介绍，要么是因为“知识诅咒”，会直接使用高阶的抽象的数学符号介绍原理，使得我迷失各种符号定义中。

之前推荐的[Python神经网络编程](https://xuzhougeng.top/archives/a-good-book-for-who-want-to-learn-deep-learning)虽然也涉及到数学，但比较浅显，在此基础上直接去阅读[动手学习深度学习](https://zh-v2.d2l.ai/index.html)这类书，还是会有很大压力，于是我找到了另一本缓冲书籍，[深度学习的数学](https://book.douban.com/subject/33414479/)

![深度学习的数学](https://halo-1252249331.cos.ap-shanghai.myqcloud.com/upload/2021/11/image-927361cba5d84a3191d846596a2360e6.png)

我个人觉得这本书最大的亮点在于，它创建了一个Excel就能训练的神经网络数据集。这个数据集一共64张图片，记录数字0和1。神经网络一共三层，输入层是12个节点，对应输入图像的12个像素点，隐藏层只有一层，3个节点，输出层是2个节点对应0和1，总计 12 x 3 + 3 + 3 x 2 + 2 = 47个参数。

由于参数少，所以作者就可以展开所有的公式，即 $z = w_1x_1 + w_2x2+ b$，而不必使用线性代数中的矩阵和向量乘法, 即 $z = w \cdot x + b$

虽然前者看起来很繁琐，不如后者简洁。但，就我而言，我更喜欢前者的直观，因为我可以自己在脑中将前者转换成后者，建立两者的联系，那么，以后看到矩阵乘法的形式，就能自动展开。

同样由于参数少，我们既可以使用Excel以线性模型的方式对代价函数优化，也可以使用Excel采取（随机）梯度下降的方式对代价函数优化。相对于使用Python根据原理手动搭建简单的神经网络，使用Excel让我们对数据有了更多的掌控感。

这本书的另一个亮点是，它涉及到数学知识刚好是我能够得上的水平。例如，在我学习「动手学习深度学习」的4.7节时，我搞不懂为什么损失函数对权重参数求导式子是下面这个样子

$$
\frac{\partial J}{\partial \mathbf{W}^{(2)}}= \text{prod}\left(\frac{\partial J}{\partial \mathbf{o}}, \frac{\partial \mathbf{o}}{\partial \mathbf{W}^{(2)}}\right) + \text{prod}\left(\frac{\partial J}{\partial s}, \frac{\partial s}{\partial \mathbf{W}^{(2)}}\right)= \frac{\partial J}{\partial \mathbf{o}} \mathbf{h}^\top + \lambda \mathbf{W}^{(2)}.
$$

看了「深度学习的数学」的2.8节才知道这是多变量函数的链式法则。

学习就相当于探险，一本合适的书会告诉我们需要了解哪些知识，这就相当于在探险过程中拿到了地图，虽然我们还没有真正抵达目的地，但起码我们知道该怎么走了，心里就有底了。

